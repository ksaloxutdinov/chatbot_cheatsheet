{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "649f23b73d914ef4be3a081b27d72724": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e4742ce382c6462fb4f021ca5aa74741",
              "IPY_MODEL_f968b6773b85479ca2191edb919fb5ec",
              "IPY_MODEL_7320781ba04e4b99a18c4615c7ff3a8b"
            ],
            "layout": "IPY_MODEL_76288d8c947e45adab12eac6363ac55f"
          }
        },
        "e4742ce382c6462fb4f021ca5aa74741": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fc7102f454b84d5da8cd192e605ddb2e",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_7b1b603d61c94c2690454460acb53221",
            "value": "model.safetensors:‚Äá‚Äá89%"
          }
        },
        "f968b6773b85479ca2191edb919fb5ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5f7a45b31dab44e6975fca2d47b2d92c",
            "max": 3087467144,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_812b0ea79d8744a0a08a73aeaff887c9",
            "value": 2750840764
          }
        },
        "7320781ba04e4b99a18c4615c7ff3a8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8d6a85393a0a47c6ab6f5995fac16081",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_0df4b0164fdb4adfbd8047c626bd4d22",
            "value": "‚Äá2.75G/3.09G‚Äá[02:00&lt;00:07,‚Äá46.5MB/s]"
          }
        },
        "76288d8c947e45adab12eac6363ac55f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fc7102f454b84d5da8cd192e605ddb2e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7b1b603d61c94c2690454460acb53221": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5f7a45b31dab44e6975fca2d47b2d92c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "812b0ea79d8744a0a08a73aeaff887c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8d6a85393a0a47c6ab6f5995fac16081": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0df4b0164fdb4adfbd8047c626bd4d22": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "bJHODe0xzG5r"
      },
      "outputs": [],
      "source": [
        "# === Cell 1: Install dependencies ===\n",
        "\n",
        "!pip install -q \\\n",
        "  transformers \\\n",
        "  accelerate \\\n",
        "  sentence-transformers \\\n",
        "  faiss-cpu \\\n",
        "  langchain \\\n",
        "  beautifulsoup4 \\\n",
        "  requests \\\n",
        "  readability-lxml\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === Cell 2: Imports, HF LLM, embeddings ===\n",
        "\n",
        "import time\n",
        "import textwrap\n",
        "from typing import List, Literal, Optional\n",
        "\n",
        "import numpy as np\n",
        "import faiss\n",
        "import torch\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from urllib.parse import urljoin, urlparse\n",
        "from urllib import robotparser\n",
        "from readability import Document as ReadabilityDocument  # NEW\n",
        "\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# Light LangChain usage (just Document type)\n",
        "try:\n",
        "    from langchain_core.documents import Document\n",
        "except ImportError:\n",
        "    from langchain.docstore.document import Document\n",
        "\n",
        "# ------------------------------------------------\n",
        "# HF LLM setup\n",
        "# ------------------------------------------------\n",
        "\n",
        "MODEL_NAME = \"Qwen/Qwen2-1.5B-Instruct\" #32K limit token size; ours +-2k\n",
        "#268 chunks from .sql(15 to 800 char)\n",
        "#outputs at 200 tokens\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "\n",
        "#both in gpu and cpu it can run; feature of huggingface\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    MODEL_NAME,\n",
        "    device_map=\"auto\",\n",
        "    torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,\n",
        ")\n",
        "\n",
        "#automated steps that transforms raw data into a trained model\n",
        "llm = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        ")\n",
        "\n",
        "print(\" Loaded HF model:\", MODEL_NAME)\n",
        "\n",
        "\n",
        "def call_llm(system_prompt: str, user_prompt: str,\n",
        "             temperature: float = 0.1,\n",
        "             max_new_tokens: int = 192) -> str:\n",
        "    prompt = (\n",
        "        f\"System:\\n{system_prompt.strip()}\\n\\n\"\n",
        "        f\"User:\\n{user_prompt.strip()}\\n\\n\"\n",
        "        f\"Assistant:\"\n",
        "    )\n",
        "\n",
        "    out = llm(\n",
        "        prompt,\n",
        "        max_new_tokens=max_new_tokens,\n",
        "        do_sample=False,\n",
        "        temperature=temperature,\n",
        "        pad_token_id=tokenizer.eos_token_id,\n",
        "    )[0][\"generated_text\"]\n",
        "\n",
        "    generated = out[len(prompt):].strip()\n",
        "    return generated\n",
        "\n",
        "\n",
        "# ------------------------------------------------\n",
        "# Shared embedding model\n",
        "# ------------------------------------------------\n",
        "#k nearest neighbors at l2 DISTANCE\n",
        "EMBEDDER_MODEL_NAME = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
        "embedder = SentenceTransformer(EMBEDDER_MODEL_NAME)\n",
        "print(\" Loaded embedder:\", EMBEDDER_MODEL_NAME)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190,
          "referenced_widgets": [
            "649f23b73d914ef4be3a081b27d72724",
            "e4742ce382c6462fb4f021ca5aa74741",
            "f968b6773b85479ca2191edb919fb5ec",
            "7320781ba04e4b99a18c4615c7ff3a8b",
            "76288d8c947e45adab12eac6363ac55f",
            "fc7102f454b84d5da8cd192e605ddb2e",
            "7b1b603d61c94c2690454460acb53221",
            "5f7a45b31dab44e6975fca2d47b2d92c",
            "812b0ea79d8744a0a08a73aeaff887c9",
            "8d6a85393a0a47c6ab6f5995fac16081",
            "0df4b0164fdb4adfbd8047c626bd4d22"
          ]
        },
        "id": "vUHPU5FzzOVl",
        "outputId": "98768b51-2376-43d8-8602-e50918e71e84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "`torch_dtype` is deprecated! Use `dtype` instead!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/3.09G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "649f23b73d914ef4be3a081b27d72724"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === Cell 3: SQL knowledge base + FAISS index (+ .sql dump) ===\n",
        "\n",
        "import os\n",
        "from typing import List\n",
        "\n",
        "sql_docs: List[str] = []\n",
        "sql_index = None\n",
        "\n",
        "\n",
        "def load_cs360_chunks_from_sql_dump(sql_path: str = \"chatbot_db_export.sql\") -> List[str]:\n",
        "    \"\"\"\n",
        "    Parse the .sql dump and extract the TEXT column from\n",
        "    COPY public.content_chunks (..., text) FROM stdin;\n",
        "    \"\"\"\n",
        "    print(f\"[load_cs360_chunks_from_sql_dump] Looking for: {sql_path}\")\n",
        "    print(f\"[load_cs360_chunks_from_sql_dump] CWD: {os.getcwd()}\")\n",
        "    print(f\"[load_cs360_chunks_from_sql_dump] Files here: {os.listdir()}\")\n",
        "\n",
        "    if not os.path.exists(sql_path):\n",
        "        print(f\"[load_cs360_chunks_from_sql_dump] File '{sql_path}' NOT found, skipping.\")\n",
        "        return []\n",
        "\n",
        "    chunks: List[str] = []\n",
        "    in_copy = False\n",
        "\n",
        "    with open(sql_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        for line in f:\n",
        "            # start of the COPY block\n",
        "            if line.startswith(\"COPY public.content_chunks\"):\n",
        "                in_copy = True\n",
        "                print(\"[load_cs360_chunks_from_sql_dump] Found COPY public.content_chunks block.\")\n",
        "                continue\n",
        "\n",
        "            if not in_copy:\n",
        "                continue\n",
        "\n",
        "            # end of the COPY block\n",
        "            if line.strip() == r\"\\.\":\n",
        "                print(\"[load_cs360_chunks_from_sql_dump] Reached end of COPY block.\")\n",
        "                break\n",
        "\n",
        "            # each line = id, document_id, topic_id, page_number, chunk_index, text\n",
        "            parts = line.rstrip(\"\\n\").split(\"\\t\", 5)\n",
        "            if len(parts) < 6:\n",
        "                continue\n",
        "\n",
        "            text = parts[5]\n",
        "            text = \" \".join(text.split())  # normalize whitespace\n",
        "            if text:\n",
        "                chunks.append(text)\n",
        "\n",
        "    print(f\"[load_cs360_chunks_from_sql_dump] Loaded {len(chunks)} chunks from {sql_path}\")\n",
        "    return chunks\n",
        "\n",
        "\n",
        "def build_sql_knowledge_base(sql_dump_path: str = \"chatbot_db_export.sql\"):\n",
        "    \"\"\"\n",
        "    Create a SQL basics KB and build a FAISS index.\n",
        "    Uses:\n",
        "      - built-in SQL snippets\n",
        "      - extra chunks parsed from chatbot_db_export.sql (if present)\n",
        "    \"\"\"\n",
        "    global sql_docs, sql_index\n",
        "\n",
        "    print(\"üîß build_sql_knowledge_base: start\")\n",
        "#12 snippets\n",
        "    sql_snippets = [\n",
        "        \"\"\"\n",
        "        SQL (Structured Query Language) is used to interact with relational databases.\n",
        "        It lets you create, read, update, and delete data (often abbreviated as CRUD).\n",
        "        \"\"\",\n",
        "        \"\"\"\n",
        "        Common SQL statements:\n",
        "        - SELECT: read data from tables\n",
        "        - INSERT: add new rows\n",
        "        - UPDATE: modify existing rows\n",
        "        - DELETE: remove rows\n",
        "        \"\"\",\n",
        "        \"\"\"\n",
        "        Basic SELECT:\n",
        "        SELECT column1, column2\n",
        "        FROM table_name\n",
        "        WHERE condition;\n",
        "        Example:\n",
        "        SELECT name, age FROM employees WHERE age > 30;\n",
        "        \"\"\",\n",
        "        \"\"\"\n",
        "        WHERE filters rows:\n",
        "        - Comparison operators: =, <>, <, >, <=, >=\n",
        "        - Logical operators: AND, OR, NOT\n",
        "        \"\"\",\n",
        "        \"\"\"\n",
        "        ORDER BY sorts rows:\n",
        "        SELECT * FROM employees ORDER BY salary DESC;\n",
        "        \"\"\",\n",
        "        \"\"\"\n",
        "        LIMIT restricts the number of rows:\n",
        "        SELECT * FROM employees LIMIT 10;\n",
        "        \"\"\",\n",
        "        \"\"\"\n",
        "        Aggregation functions:\n",
        "        - COUNT(*)\n",
        "        - SUM(column)\n",
        "        - AVG(column)\n",
        "        - MIN(column)\n",
        "        - MAX(column)\n",
        "        Often used with GROUP BY.\n",
        "        \"\"\",\n",
        "        \"\"\"\n",
        "        GROUP BY groups rows by column(s):\n",
        "        SELECT department, COUNT(*)\n",
        "        FROM employees\n",
        "        GROUP BY department;\n",
        "        \"\"\",\n",
        "        \"\"\"\n",
        "        Joins combine rows from multiple tables:\n",
        "        - INNER JOIN: only matching rows\n",
        "        - LEFT JOIN: all from left table + matches from right\n",
        "        - RIGHT JOIN: all rows from both tables\n",
        "        \"\"\",\n",
        "        \"\"\"\n",
        "        INNER JOIN example:\n",
        "        SELECT e.name, d.name\n",
        "        FROM employees e\n",
        "        INNER JOIN departments d\n",
        "          ON e.department_id = d.id;\n",
        "        \"\"\",\n",
        "        \"\"\"\n",
        "        CREATE TABLE example:\n",
        "        CREATE TABLE employees (\n",
        "            id INT PRIMARY KEY,\n",
        "            name VARCHAR(100),\n",
        "            age INT,\n",
        "            salary DECIMAL(10,2)\n",
        "        );\n",
        "        \"\"\",\n",
        "        \"\"\"\n",
        "        INSERT example:\n",
        "        INSERT INTO employees (id, name, age, salary)\n",
        "        VALUES (1, 'Alice', 30, 5000.00);\n",
        "        \"\"\",\n",
        "    ]\n",
        "\n",
        "    # base snippets (cleaned)\n",
        "    docs: List[str] = [\" \".join(sn.split()) for sn in sql_snippets]\n",
        "    print(f\"   Base SQL snippets: {len(docs)}\")\n",
        "\n",
        "    # extra chunks from .sql dump\n",
        "    extra_chunks = load_cs360_chunks_from_sql_dump(sql_dump_path)\n",
        "    if extra_chunks:\n",
        "        docs.extend(extra_chunks)\n",
        "        print(f\"Added {len(extra_chunks)} chunks from {sql_dump_path} into SQL KB.\")\n",
        "    else:\n",
        "        print(\"No extra chunks loaded from .sql dump.\")\n",
        "\n",
        "    if not docs:\n",
        "        print(\" No SQL docs found. SQL KB will be empty.\")\n",
        "        sql_docs = []\n",
        "        sql_index = None\n",
        "        return\n",
        "\n",
        "    print(f\" Total docs/chunks to index: {len(docs)}\")\n",
        "\n",
        "    embeddings = embedder.encode(docs, convert_to_numpy=True, show_progress_bar=False)\n",
        "    dim = embeddings.shape[1]\n",
        "    index = faiss.IndexFlatL2(dim)\n",
        "    index.add(embeddings)\n",
        "\n",
        "    sql_docs = docs\n",
        "    sql_index = index\n",
        "    print(\"SQL KB built with\", len(sql_docs), \"documents.\")\n",
        "\n",
        "\n",
        "def retrieve_sql_context(query: str, top_k: int = 5) -> List[str]:\n",
        "    \"\"\"\n",
        "    RAG retrieval for SQL mode.\n",
        "    \"\"\"\n",
        "    if sql_index is None or not sql_docs:\n",
        "        return []\n",
        "\n",
        "    q_emb = embedder.encode([query], convert_to_numpy=True, show_progress_bar=False)\n",
        "    k = min(top_k, len(sql_docs))\n",
        "    D, I = sql_index.search(q_emb, k)\n",
        "    return [sql_docs[i] for i in I[0]]\n"
      ],
      "metadata": {
        "id": "fCkzlbmNzwsq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Cell 4: sqlbolt.com crawler + FAISS index (robust) ===\n",
        "\n",
        "from typing import List, Optional\n",
        "from urllib.parse import urljoin, urlparse\n",
        "from urllib import robotparser\n",
        "import time\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from readability import Document as ReadabilityDocument\n",
        "import faiss\n",
        "\n",
        "sqlbolt_docs: List[str] = []\n",
        "sqlbolt_index = None\n",
        "\n",
        "def build_robot_parser(base_url: str) -> Optional[robotparser.RobotFileParser]:\n",
        "    robots_url = urljoin(base_url, \"/robots.txt\")\n",
        "    rp = robotparser.RobotFileParser()\n",
        "    try:\n",
        "        rp.set_url(robots_url)\n",
        "        rp.read()\n",
        "        print(f\"Loaded robots.txt from {robots_url}\")\n",
        "    except Exception as e:\n",
        "        print(\"Could not read robots.txt, assuming allow-all. Error:\", e)\n",
        "    return rp\n",
        "\n",
        "def is_allowed(url: str, rp: Optional[robotparser.RobotFileParser], user_agent: str = \"*\") -> bool:\n",
        "    if rp is None:\n",
        "        return True\n",
        "    try:\n",
        "        return rp.can_fetch(user_agent, url)\n",
        "    except Exception:\n",
        "        return True\n",
        "\n",
        "def fetch_page(url: str, timeout: int = 10) -> Optional[str]:\n",
        "    headers = {\n",
        "        \"User-Agent\": \"Mozilla/5.0 (compatible; SQLBoltRAGBot/1.0; +https://sqlbolt.com/)\"\n",
        "    }\n",
        "    try:\n",
        "        resp = requests.get(url, headers=headers, timeout=timeout)\n",
        "        if resp.status_code == 200 and \"text/html\" in resp.headers.get(\"Content-Type\", \"\"):\n",
        "            return resp.text\n",
        "        else:\n",
        "            print(f\"Skip {url} (status {resp.status_code}, type {resp.headers.get('Content-Type')})\")\n",
        "    except Exception as e:\n",
        "        print(\"Error fetching\", url, \"->\", e)\n",
        "    return None\n",
        "\n",
        "def extract_clean_text(html: str) -> str:\n",
        "    \"\"\"\n",
        "    Try readability-lxml to get main article text, fall back to full page\n",
        "    if needed. Strip typical boilerplate tags.\n",
        "    \"\"\"\n",
        "    soup = None\n",
        "\n",
        "    # 1) try readability main content\n",
        "    try:\n",
        "        doc = ReadabilityDocument(html)\n",
        "        main_html = doc.summary()\n",
        "        soup = BeautifulSoup(main_html, \"html.parser\")\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "    # 2) fallback: whole page\n",
        "    if soup is None:\n",
        "        soup = BeautifulSoup(html, \"html.parser\")\n",
        "\n",
        "    # remove junk\n",
        "    for tag in soup([\"script\", \"style\", \"noscript\", \"header\", \"footer\", \"nav\", \"form\"]):\n",
        "        tag.decompose()\n",
        "\n",
        "    text = soup.get_text(\" \", strip=True)\n",
        "    text = \" \".join(text.split())\n",
        "    return text\n",
        "\n",
        "def chunk_text(text: str, max_chars: int = 700) -> List[str]:\n",
        "    \"\"\"\n",
        "    Simple fixed-size character chunking.\n",
        "    \"\"\"\n",
        "    text = \" \".join(text.split())\n",
        "    if not text:\n",
        "        return []\n",
        "    chunks = []\n",
        "    start = 0\n",
        "    while start < len(text):\n",
        "        end = start + max_chars\n",
        "        chunks.append(text[start:end])\n",
        "        start = end\n",
        "    return chunks\n",
        "\n",
        "def crawl_and_build_sqlbolt_index(\n",
        "    start_url: str = \"https://sqlbolt.com/\",\n",
        "    max_pages: int = 100,\n",
        "    sleep_sec: float = 1.0\n",
        "):\n",
        "    \"\"\"\n",
        "    Crawl sqlbolt.com and build a FAISS index over collected text chunks.\n",
        "    Logs how many pages and chunks we end up with.\n",
        "    \"\"\"\n",
        "    global sqlbolt_docs, sqlbolt_index\n",
        "\n",
        "    visited = set()\n",
        "    queue = [start_url]\n",
        "    domain = urlparse(start_url).netloc\n",
        "    rp = build_robot_parser(start_url)\n",
        "\n",
        "    collected_chunks: List[str] = []\n",
        "    pages_with_text = 0\n",
        "\n",
        "    while queue and len(visited) < max_pages:\n",
        "        url = queue.pop(0)\n",
        "        url = url.split(\"#\")[0]\n",
        "        if url in visited:\n",
        "            continue\n",
        "        visited.add(url)\n",
        "\n",
        "        if not is_allowed(url, rp):\n",
        "            print(\"Disallowed by robots.txt, skipping:\", url)\n",
        "            continue\n",
        "\n",
        "        print(f\"Crawling ({len(visited)}/{max_pages}): {url}\")\n",
        "        html = fetch_page(url)\n",
        "        if not html:\n",
        "            continue\n",
        "\n",
        "        text = extract_clean_text(html)\n",
        "        # VERY permissive now: keep even small pages\n",
        "        if len(text) < 50:\n",
        "            print(\"  -> very short page, skipping (len =\", len(text), \")\")\n",
        "        else:\n",
        "            chunks = chunk_text(text, max_chars=700)\n",
        "            if chunks:\n",
        "                pages_with_text += 1\n",
        "                collected_chunks.extend(chunks)\n",
        "                print(f\"  -> kept {len(chunks)} chunks (total chunks: {len(collected_chunks)})\")\n",
        "\n",
        "        # discover more links\n",
        "        soup = BeautifulSoup(html, \"html.parser\")\n",
        "        for a in soup.find_all(\"a\", href=True):\n",
        "            href = a[\"href\"].strip()\n",
        "            if href.startswith(\"#\"):\n",
        "                continue\n",
        "            full_url = urljoin(url, href)\n",
        "            parsed = urlparse(full_url)\n",
        "            if parsed.netloc == domain and full_url not in visited:\n",
        "                queue.append(full_url)\n",
        "\n",
        "        time.sleep(sleep_sec)\n",
        "\n",
        "    print(f\"\\nVisited pages: {len(visited)}, pages with text: {pages_with_text}\")\n",
        "    print(f\"Total chunks collected: {len(collected_chunks)}\")\n",
        "\n",
        "    if not collected_chunks:\n",
        "        print(\" No text collected from sqlbolt.com. Index will NOT be built.\")\n",
        "        sqlbolt_docs = []\n",
        "        sqlbolt_index = None\n",
        "        return\n",
        "\n",
        "    sqlbolt_docs = collected_chunks\n",
        "    embeddings = embedder.encode(sqlbolt_docs, convert_to_numpy=True, show_progress_bar=False)\n",
        "    dim = embeddings.shape[1]\n",
        "    index = faiss.IndexFlatL2(dim)\n",
        "    index.add(embeddings)\n",
        "    sqlbolt_index = index\n",
        "\n",
        "    print(\"sqlbolt.com index built with\", len(sqlbolt_docs), \"chunks.\")\n",
        "\n",
        "\n",
        "def retrieve_sqlbolt_context(query: str, top_k: int = 5) -> List[str]:\n",
        "    if sqlbolt_index is None or not sqlbolt_docs:\n",
        "        return []\n",
        "    q_emb = embedder.encode([query], convert_to_numpy=True, show_progress_bar=False)\n",
        "    k = min(top_k, len(sqlbolt_docs))\n",
        "    D, I = sqlbolt_index.search(q_emb, k)\n",
        "    return [sqlbolt_docs[i] for i in I[0]]\n"
      ],
      "metadata": {
        "id": "9iYYd645zzSU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Cell 5: Answer verification (anti-hallucination, tuned) ===\n",
        "\n",
        "from typing import List\n",
        "import numpy as np\n",
        "\n",
        "def clean_llm_output(raw: str) -> str:\n",
        "    \"\"\"\n",
        "    Strip obvious prompt echoes and role labels.\n",
        "    \"\"\"\n",
        "    text = raw.strip()\n",
        "    for tag in [\"Assistant:\", \"ASSISTANT:\", \"System:\", \"User:\"]:\n",
        "        if text.startswith(tag):\n",
        "            text = text.split(tag, 1)[1].strip()\n",
        "\n",
        "    for tag in [\"System:\", \"User:\", \"<CONTEXT>\", \"</CONTEXT>\"]:\n",
        "        if tag in text:\n",
        "            text = text.split(tag, 1)[0].strip()\n",
        "\n",
        "    return text.strip()\n",
        "\n",
        "\n",
        "def verify_answer(\n",
        "    answer: str,\n",
        "    context_texts: List[str],\n",
        "    threshold: float = 0.45,   #0.65 was too strict\n",
        "    min_overlap: int = 1       # require at least 1 shared meaningful word\n",
        ") -> str:\n",
        "    \"\"\"\n",
        "    1) Embed answer + context and check cosine similarity.\n",
        "    2) Check that answer shares words with context.\n",
        "    If not ‚Üí \"Not enough information.\"\n",
        "    \"\"\"\n",
        "    if not context_texts:\n",
        "        return \"Not enough information.\"\n",
        "\n",
        "    answer_text = \" \".join(answer.split())\n",
        "    context_texts = [\" \".join(c.split()) for c in context_texts]\n",
        "\n",
        "    # Embedding similarity\n",
        "    answer_emb = embedder.encode(\n",
        "        [answer_text], convert_to_numpy=True, show_progress_bar=False\n",
        "    )\n",
        "    context_embs = embedder.encode(\n",
        "        context_texts, convert_to_numpy=True, show_progress_bar=False\n",
        "    )\n",
        "\n",
        "    cos_sim = np.dot(answer_emb, context_embs.T) / (\n",
        "        np.linalg.norm(answer_emb) * np.linalg.norm(context_embs, axis=1)\n",
        "    )\n",
        "\n",
        "    max_sim = float(np.max(cos_sim))\n",
        "    # print(\"DEBUG max_sim:\", max_sim)  # optional debug\n",
        "\n",
        "    if max_sim < threshold:\n",
        "        return \"Not enough information.\"\n",
        "\n",
        "    # Word-overlap sanity check\n",
        "    flat_context = \" \".join(context_texts).lower()\n",
        "    answer_lower = answer_text.lower()\n",
        "    words = [w for w in answer_lower.split() if len(w) > 3]\n",
        "\n",
        "    relevant_words = [w for w in words if w in flat_context]\n",
        "\n",
        "    if len(relevant_words) < min_overlap:\n",
        "        return \"Not enough information.\"\n",
        "\n",
        "    return answer_text\n"
      ],
      "metadata": {
        "id": "sydTg1Pvz28G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Cell 6: RAG answer generation for SQL + sqlbolt.com QA (generative) ===\n",
        "\n",
        "import re\n",
        "import textwrap\n",
        "from typing import Literal, List\n",
        "\n",
        "def _extract_snippet(chunk: str, query: str, window: int = 260) -> str:\n",
        "    \"\"\"\n",
        "    (Still here if you want snippet mode later, but NOT used in sqlbolt now)\n",
        "    \"\"\"\n",
        "    text = \" \".join(chunk.split())\n",
        "    if not text:\n",
        "        return \"\"\n",
        "\n",
        "    words = [w for w in query.lower().split() if len(w) > 3]\n",
        "    lower_text = text.lower()\n",
        "\n",
        "    idx = -1\n",
        "    for w in words:\n",
        "        pos = lower_text.find(w)\n",
        "        if pos != -1:\n",
        "            idx = pos\n",
        "            break\n",
        "\n",
        "    if idx == -1:\n",
        "        snippet = text[:window]\n",
        "        return snippet + (\"...\" if len(text) > window else \"\")\n",
        "\n",
        "    start = max(idx - window // 2, 0)\n",
        "    end = min(len(text), start + window)\n",
        "    snippet = text[start:end]\n",
        "    if start > 0:\n",
        "        snippet = \"...\" + snippet\n",
        "    if end < len(text):\n",
        "        snippet = snippet + \"...\"\n",
        "    return snippet\n",
        "\n",
        "\n",
        "def strip_inner_not_enough_information(text: str) -> str:\n",
        "    \"\"\"\n",
        "    If the model wrote a real answer *and then* added some\n",
        "    'not enough information' sentence, drop that sentence.\n",
        "    If the entire answer is just that phrase, keep it.\n",
        "    \"\"\"\n",
        "    t = text.strip()\n",
        "    lower = t.lower()\n",
        "\n",
        "    # if whole answer is basically \"not enough information\", keep it\n",
        "    if \"not enough information\" in lower and len(t.split()) < 6:\n",
        "        return t\n",
        "\n",
        "    # otherwise, cut off anything from 'not enough information' onwards\n",
        "    marker_idx = lower.find(\"not enough information\")\n",
        "    if marker_idx != -1:\n",
        "        return t[:marker_idx].rstrip()\n",
        "\n",
        "    return t\n",
        "\n",
        "\n",
        "def _answer_from_sqlbolt(query: str) -> str:\n",
        "    \"\"\"\n",
        "    Generative answer using context from sqlbolt.com:\n",
        "\n",
        "    - Retrieve relevant chunks from the crawled pages\n",
        "    - Feed them to the LLM with a strict 'use ONLY this context' prompt\n",
        "    - Verify the answer against the context\n",
        "    \"\"\"\n",
        "    ctx = retrieve_sqlbolt_context(query, top_k=8)\n",
        "    if not ctx:\n",
        "        return \"Not enough information.\"\n",
        "\n",
        "    system_prompt = textwrap.dedent(\"\"\"\n",
        "        You are an SQL teaching assistant.\n",
        "        The context comes from sqlbolt.com.\n",
        "        You MUST answer using ONLY the information in the provided context.\n",
        "        If the context does not contain enough information to answer,\n",
        "        reply exactly: Not enough information.\n",
        "        Do NOT invent new examples, syntax, or explanations beyond the context.\n",
        "        Keep your answer concise and clear.\n",
        "    \"\"\")\n",
        "\n",
        "    context_text = \"\\n\\n---\\n\\n\".join(ctx)\n",
        "\n",
        "    user_prompt = textwrap.dedent(f\"\"\"\n",
        "        <CONTEXT>\n",
        "        {context_text}\n",
        "        </CONTEXT>\n",
        "\n",
        "        Question: {query}\n",
        "\n",
        "        Answer the question using ONLY the information inside <CONTEXT>.\n",
        "        If the answer is not fully supported by the context,\n",
        "        reply exactly: Not enough information.\n",
        "    \"\"\")\n",
        "\n",
        "    raw = call_llm(system_prompt, user_prompt, temperature=0.1, max_new_tokens=192)\n",
        "    cleaned = clean_llm_output(raw)\n",
        "    final_answer = verify_answer(cleaned, ctx, threshold=0.45)\n",
        "    final_answer = strip_inner_not_enough_information(final_answer)\n",
        "    return final_answer\n",
        "\n",
        "\n",
        "def generate_rag_answer(query: str, mode: Literal[\"sql\", \"sqlbolt\"]) -> str:\n",
        "    \"\"\"\n",
        "    Core RAG:\n",
        "\n",
        "    - mode == \"sql\":\n",
        "        * retrieve SQL context (local KB)\n",
        "        * use LLM with strict instructions\n",
        "        * verify answer against context\n",
        "\n",
        "    - mode == \"sqlbolt\":\n",
        "        * retrieve sqlbolt.com context\n",
        "        * same pattern, but using sqlbolt chunks\n",
        "    \"\"\"\n",
        "    if mode == \"sql\":\n",
        "        context_chunks = retrieve_sql_context(query, top_k=8)\n",
        "        if not context_chunks:\n",
        "            return \"Not enough information.\"\n",
        "\n",
        "        system_prompt = textwrap.dedent(\"\"\"\n",
        "            You are an SQL teaching assistant.\n",
        "            You MUST answer using ONLY the information in the provided context.\n",
        "            If the context does not contain enough information to answer,\n",
        "            reply exactly: Not enough information.\n",
        "            Do NOT invent new examples, syntax, or explanations beyond the context.\n",
        "            Keep your answer concise and clear.\n",
        "        \"\"\")\n",
        "\n",
        "        context_text = \"\\n\\n---\\n\\n\".join(context_chunks)\n",
        "\n",
        "        user_prompt = textwrap.dedent(f\"\"\"\n",
        "            <CONTEXT>\n",
        "            {context_text}\n",
        "            </CONTEXT>\n",
        "\n",
        "            Question: {query}\n",
        "\n",
        "            Answer the question using ONLY the information inside <CONTEXT>.\n",
        "            If the answer is not fully supported by the context,\n",
        "            reply exactly: Not enough information.\n",
        "        \"\"\")\n",
        "\n",
        "        raw = call_llm(system_prompt, user_prompt, temperature=0.1, max_new_tokens=192)\n",
        "        cleaned = clean_llm_output(raw)\n",
        "        final_answer = verify_answer(cleaned, context_chunks, threshold=0.45)\n",
        "        final_answer = strip_inner_not_enough_information(final_answer)\n",
        "        return final_answer\n",
        "\n",
        "    elif mode == \"sqlbolt\":\n",
        "\n",
        "        return _answer_from_sqlbolt(query)\n",
        "\n",
        "    else:\n",
        "        return \"Unknown mode.\"\n"
      ],
      "metadata": {
        "id": "2blsSJcqz5H5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Cell 7: Build SQL KB + crawl sqlbolt.com & build index ===\n",
        "\n",
        "print(\"Building SQL knowledge base...\")\n",
        "build_sql_knowledge_base()\n",
        "\n",
        "print(\"\\n Crawling sqlbolt.com and building index (this may take a bit)...\")\n",
        "crawl_and_build_sqlbolt_index(\n",
        "    start_url=\"https://sqlbolt.com/\",\n",
        "    max_pages=100,   # adjustable\n",
        "    sleep_sec=1.0\n",
        ")\n",
        "\n",
        "print(\"\\n RAG indexes ready.\")\n"
      ],
      "metadata": {
        "id": "eVPSp6u5z7AF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Cell 8: Console chatbot (sql + sqlbolt) ===\n",
        "\n",
        "\n",
        "print(\"Modes:\")\n",
        "print(\"  - 'sql'     ‚Üí SQL tutor (local KB)\")\n",
        "print(\"  - 'sqlbolt' ‚Üí sqlbolt.com QA\")\n",
        "print(\"Commands:\")\n",
        "print(\"  - type 'mode sql' or 'mode sqlbolt' to switch\")\n",
        "print(\"  - type 'exit' to quit\\n\")\n",
        "\n",
        "current_mode: Literal[\"sql\", \"sqlbolt\"] = \"sql\"\n",
        "print(f\"Current mode: {current_mode}\")\n",
        "\n",
        "while True:\n",
        "    user_inp = input(f\"[{current_mode}] You: \").strip()\n",
        "    if not user_inp:\n",
        "        continue\n",
        "\n",
        "    low = user_inp.lower()\n",
        "\n",
        "    if low in [\"exit\", \"quit\", \"stop\"]:\n",
        "        print(\"Goodbye!\")\n",
        "        break\n",
        "\n",
        "    # --- STRICT mode switching ---\n",
        "    if low.startswith(\"mode\"):\n",
        "        parts = low.split()\n",
        "        if len(parts) == 2:\n",
        "            target = parts[1]\n",
        "            if target in (\"sqlbolt\", \"sqlbot\"):   # accept both spellings\n",
        "                current_mode = \"sqlbolt\"\n",
        "                print(\"üîÅ Switched to sqlbolt.com QA mode.\")\n",
        "                continue\n",
        "            elif target == \"sql\":\n",
        "                current_mode = \"sql\"\n",
        "                print(\"üîÅ Switched to SQL tutor mode.\")\n",
        "                continue\n",
        "        print(\"Unknown mode. Use 'mode sql' or 'mode sqlbolt'.\")\n",
        "        continue\n",
        "\n",
        "    # --- RAG answer ---\n",
        "    answer = generate_rag_answer(user_inp, mode=current_mode)\n",
        "    print(f\"AI: {answer}\\n\")\n"
      ],
      "metadata": {
        "id": "mkGLH7wqz9iu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "38-jbTqdALnP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}